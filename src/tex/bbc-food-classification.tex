\documentclass[11pt,a4paper]{article}

\usepackage{verbatim}
\usepackage{graphicx}
\usepackage{float}
\floatstyle{boxed}
\restylefloat{figure}
\usepackage{mathtools}

\title{Decision Tree Classification of Cuisines for BBC Food Recipes}
\author{Ross Fenning}

\begin{document}

\maketitle

\section{Introduction}

Most recipes in modern, British cooking have
originated in several different cultures and cuisines, such as Indian,
Italian or French. Some, like British and French, have arguably a lot
of crossover, whilst some are much more further apart.

Other cuisines might seem superficially different to people, such as Indian and
South-east Asian cuisines, but perhaps they overlap in a lot of their
ingredients due to relative geographical proximity?

\subsection{The Problem}

This coursework will explore applying supervised machine learning
techniques on food recipes and within it, we hope to create a model for
identifying the cultural origin of a recipe from the ingredients used
therein.

The BBC Food website provides a searchable collection of around 15,000
recipes created by professional TV chefs -- spanning twenty different
cuisines -- all of which comprise ingredients, preparation steps and
further metadata such as suitability for specific diets (e.g.
vegetarian) and expected time required to prepare the meal.

However, only around a third of the recipes have actually been manually
categorised as to which cuisine they are. Marking the remaining
two-thirds with their respective cuisine would be further manual effort
by editorial staff. A model that is able to assign or at least suggest
a cuisine based on supervised learning from the known set could be a useful
tool in improving the metadata on BBC Food recipes.

\subsection{Attributes}

A recipe can be said to have the following attributes:

\begin{itemize}
\item Ingredients
\item Preparation steps
\item Preparation time
\item Cooking time
\item Number of people it will serve
\item Cuisine
\item Special diets for which it may or may not be suitable
  (e.g. vegetarian, dairy-free)
\item Whether it's in season
\item For which course it is suitable (e.g. starter, dessert).
\item Whether it pertains to an occasion (e.g. Burn's Night, Christmas)
\item Which BBC programme has featured the recipe
\item Which chef created the recipe
\end{itemize}

For simplicity, we will focus initially on classifying by the cuisine attribute
(i.e. using that attribute as the class) based on the ingredients expressed as
vector of binary, nominal attributes, i.e. the ``carrot'' attribute is
\emph{true} if and only if the given recipe contains carrots.

Whether a recipe is in season is a transient attribute, but could possibly be
used in a different problem of learning which recipes are in season in different
times of the year. The chef and TV programmes that featured the recipe are
also out of scope for our problem, but could lead to an interesting machine
learning problem of trying to identify typical trends in recipes created by
particular chefs.

Occasion is categorical attribute that marks certain recipes as being typical
dishes served at particular festivals and celebrations. This could lead to
another classification problem, but for cuisine classification, it is likely to
be reasonably redundant due to the cultural basis of such festivals. For
instance, there are unlikely to be many Italian Burn's Night dishes nor Mexican
Diwali recipes.

The numerical attributes such as number of people the recipe is to serve or the
number of steps in the cooking method seem fairly arbitrary with respect to the
ingredients involved or the cuisine. This indicates the problem is very much
dealing with categorical attributes.

\section{BBC Food Dataset}

\subsection{Structure}

Figure~\ref{model} shows a simplified view of a data model for the BBC Food
domain. There are many more objects for functional aspects of the pages, but
the items included in the diagram capture enough to model the recipe content.

A recipe is broken up into \emph{stages} representing some discrete part of the
overall recipe, e.g. the filling and the pastry are two separate stages for
making a pie. Recipes that do not break up into stages default to having a single
stage that represents the whole dish.

It is the stages then that map to one or more \emph{ingredients} which represent
a specific quantity of a food item. For example, \emph{200g Flour} would be an
\emph{ingredient} with the flour being the \emph{food} and 200g being the
\emph{quantity}.

\begin{comment}
  @startuml food_data_model.png
  
  skinparam monochrome true
  skinparam circledCharacterRadius 0
  skinparam circledCharacterFontSize 0
  skinparam classFontSize 20
  
  class Recipe
  class Stage
  class Cuisine
  class Ingredient {
    quantity
  }
  class Food
  class Diet
  class Method
  class Chef {
    firstName
    surname
  }
  class Programme
  class Occasion
  
  Recipe "0..*" -u- "1" Cuisine
  Recipe "1" -d- "1..*" Stage
  Stage "1" -- "1..*" Ingredient
  Ingredient "1..*" -r- "1" Food
  Diet "0..*" -- "0..*" Recipe
  Recipe "1" -l- "1..*" Method
  Recipe "1..*" -- "1" Chef
  Recipe "1..*" -r- "0..*" Programme
  Recipe "0..*" -d- "0..*" Occasion
  Food "0..*" -u- "0..*" Occasion
  
  @enduml
\end{comment}
\begin{figure}[p]
  \begin{center}
    \includegraphics[width=\linewidth]{food_data_model.png}
  \end{center}
  \caption{Recipe domain model\label{model}}
\end{figure}

We can see that an \emph{Occasion} can be linked to either a food or a recipe.
For instance, \emph{Christmas} is linked both to the food \emph{mincemeat} and
the recipe \emph{Christmas turkey and stuffing}.

A recipe also comprises one or many \emph{methods}, which represent the list
of instructions to follow in order to prepare the dish. This is textual data
intended for human reading and is not useful as an attribute for machine
learning. It could be possible to massage some attributes out of these steps
using natural language techniques, but that is not explored here.

Finally, we can see that recipes also have the additional attributes of
diets, chefs and programmes.

Focusing on the cuisine attribute, Figure~\ref{cuisine-set} shows how many
recipes are assigned to a cuisine on the BBC Food website.

\begin{figure}[p]
  \includegraphics[width=\linewidth]{cuisine_set.png}
  \caption{Number of recipes that have a cuisine on BBC Food\label{cuisine-set}}
\end{figure}

It seems that approximately 30\% of the recipes on the BBC Food website are
assigned whilst 70\% haven't been categorised in this way. Given that one
such uncategorised recipe is
\emph{American herb pancakes with cottage cheese and pastrami}, which indicates
its country of origin in the title, it would appear that the cuisine categories
are missing due to a lack of time or resources to add them by hand. This
strengthens the utility of a model or system that could pre-populate the cuisine
category automatically.

\subsection{Visualisation of different classes}


\section{Classification}

As stated in the introduction, we will be exploring supervised learning techniques
on this recipe dataset and the primary focus will be developing an expert system
that can classify the cuisine from a recipe's ingredients. In this section,
we will be attempting to train such a classifier, evaluate it and then
look to ways to improve the model it produces.

Firstly, we can explore the dataset even further with respect to the cuisine class.
This starts with taking the relational structure shown in Figure~\ref{model} and
preparing the data to be ready for data mining and machine learning techniques.

\subsection{Flattening the recipes}

In machine learning, we are concerned with training models on sets of \emph{instances}
of a particular relation. It is therefore necessary to take largely structured
data such as that shown by Figure~\ref{model} and flatten or denormalise it into
a single relation. A single relation is then easy to express in CSV or ARFF file
formats for applications that can read them and provide analysis or mining:

\begin{equation} \label{recipe-tuple}
(cuisine, ingredient_1, ingredient_2, ... ,ingredient_N)
\end{equation}

In \eqref{recipe-tuple} all ingredients are converted to nominal, binary attributes
with values \emph{false} and \emph{true} to reflect whether that recipe contains
each of the possible ingredients or not. The cuisine attribute is a nominal
attribute which is serving as our class attribute.

Thus a single instance would be, for example:

\begin{equation} \label{recipe-example}
(Italian, True, False, ... ,True)
\end{equation}


\subsection{Exploring the Dataset}

The breakdown of the cuisine category is shown in Figure~\ref{cuisines-barchart}
for only those recipes that have a cuisine set.

\begin{figure}[p]
  \includegraphics[width=\linewidth]{cuisines.png}
  \caption{Number of recipes for each cuisine on BBC Food\label{cuisines-barchart}}
\end{figure}

British recipes are clearly dominant, which is likely not surprisingly for the
BBC, but it might also be a symptom of British cooking's tendancy to borrow and
derive from
many other cultures. A classification model might show deeper insight into which
cultures overlap most with British cuisine.

At the other end of the spectrum, there are some cuisines that have a very small
number of recipes. Portguese has the lowest at only 14 recipes and African
cooking has only 18 instances. These categories might be tricky when it comes to
classification as any model born out of a supervised learning process will not
have been exposed to many examples therein.

Looking at the ingredients attributes, we can see in Figure~\ref{top-ingredients}
that the number of recipes that contain the top 50 ingredients follows a
Pareto-looking curve when the ingredients themselves are arranged in descending
order of their appearance.

\begin{figure}[p]
  \includegraphics[width=\linewidth]{top_ingredients_counts.png}
  \caption{Number of recipes that use the top 50 ingredients\label{top-ingredients}}
\end{figure}

Perhaps unsurprisingly for a collection of professional recipes, olive oil is the most
common ingredient. The popular foods all seem to be very common ingredients to most
dishes, but this quickly descends to a long tail of foods that only appear in a few
of the recipes. In fact, 9\% of the foods only appear in a single recipe.
Figure~\ref{ingredients-counts} shows the full curve when we include all of the
ingredients.

\begin{figure}[p]
  \includegraphics[width=\linewidth]{ingredients_counts.png}
  \caption{Descending frequency distribution of ingredients' appearances in recipes\label{ingredients-counts}}
\end{figure}

\subsubsection{Data Reduction}

It may be preferable to clean the data of ingredients
with too common an appearance as the amount of
self-information \cite{reza1961introduction} for a very common ingredient is low. For
instance if asked to guess the classification of an unseen recipe given only
the information that it contains olive oil, it is clear that little information
has been given. We can run any classification on both the full set of ingredients
and reduced versions thereof (i.e. projections into fewer dimensions) and compare
the models to evaluate the benefits of preprocessing the data in this way.

There may also be some benefit to reducing the dataset by removing the most rare
ingredients. Whilst their self-information is high (nearly 14 bits for ingredients
that only appear in one recipe compared to 0.8 bits for olive oil), they could
easily contribute to a model that overfits the data.

Overfitting occurs when the model becomes over-trained to the specific training set
used and becomes less useful for applying to new, unclassified instances. It has
been shown \cite{tetko1995neural} with neural network classifiers, that whilst the
classification error against a learning set gradually decreases over time, the
ability for that trained network to predict categories on instances outside of the
learning set follows a parabolic curve and starts to increase after passing a
minimum.

The likely explanation \cite{tetko1995neural} is that classifiers will find underlying
relations between attributes in the early iterations, but when the number of iterations
exceeds the optimum point, it is starting to learn noise and random correlations that
appear within that noise.

To use a real example from the recipe dataset, only one recipe in the set of
classified recipes uses tortellini as an ingredient: \emph{Tortellini in sarcofago}.
This recipe also happens to be classified as Italian cuisine, which means a classifier
that infers:

\begin{equation} \label{tortellini-rule}
has\_tortellini(X) \to italian(X)
\end{equation}

\noindent would be 100\% correct on that particular
rule given the training set, but it should be intuitively clear that the confidence
thereof is very low. This relates to the usage of \emph{pessimistic pruning} employed
by the C4.5 algorithm \cite{quinlan1993c4} on decision trees constructed by that algorithm.
Pessimistic pruning uses an upper bound on the probability of error for a given classification
based on the confidence limits for the binomial distribution.

If we follow the na\"ive approach used in pessimistic pruning and treat the error rate
of \eqref{tortellini-rule} as being $0$ error ``events'' out of $1$ ``trials'' (i.e.
we classified only one recipe with it and we were 100\% correct and 0\% wrong), then
the upper bound on likelihood of the rule being erroneous at 90\% confidence is
actually 95\% using the Clopper-Pearson method. \cite{clopper1934use}

Hopefully, it should be clear that it is probably suboptimal to build a model from
a learned rule that has a 0\% error rate on the training dataset, but
on the population of recipes as a whole could
have an error rate up to 95\% based on an -- admittedly na\"ive -- application of
confidence intervals and a pessimistic interpretation thereof.
Such a rule is a good indication of a model that has overfit
its learning dataset and is justification for either post-pruning using Quinlan's
pessimistic pruning or preventing through a data reduction step that removes rare
ingredients before any data mining even takes place.

In tandem with the desire to prevent overfitting of the data, is a desire to build
the smallest model or tree possible that best classifies the recipes. This
aim is expressed both by Quinlan when introducing C4.5 \cite{quinlan1993c4}
and by Witten and Frank \cite{witten2005data}, who introduce the
\emph{Minimum Description Length}, or MDL, principle. This principle is
described as being a manifestation of \emph{Occam's Razor} within machine learning
in that we prefer the simplest theory (i.e. classification model) that describes
the evidence (i.e. the dataset). They describe the goal of trying to choose
theory $T$ given the evidence $E$ that maximises the posteriori probability:

\begin{equation}
Pr(T | E)
\end{equation}

\noindent as being equivalent to trying to minimise the number of bits necessary
to describe the theory and its informational loss:

\begin{equation}
L(T) + L(E | T)
\end{equation}

It could be that one way to ensure we achieve the smallest model possible is eagerly to remove
attributes and dimensions that we can predict with some confidence are unlikely
to contribute to the final expert system produced.

It may be the case however that little is gained by pre-emptively removing
ingredients that are unlikely to be helpful for classification. If we are to use an Inductive
Decision Tree classification approach such as ID3 \cite{quinlan1986induction}
or C4.5 \cite{quinlan1993c4}, then the algorithm should endeavour to build
rules based on ingredients that best classify the cuisines. It should be expected
in an optimal solution therefore that pre-emptive reduction of the ingredients
attributes is unnecessary as the less indicative ingredients will not be used
near the top of the tree. We would then achieve a minimal model but halting
the tree construction at the error minimum point before overfitting starts
to occur as described by Tetko, Livingstone and Luik, \cite{tetko1995neural}
which should be the point at which the attributes that have genuine relationships
have been modelled, but before the point at which outlier attributes such as
\emph{tortellini} above (which could be considered noise) start to affect the
classification.

Unfortunately, the assumption that the algorithm alone will behave optimally in this
way cannot be relied upon. Constructing an optimal decision tree is shown to be
an NP-complete problem \cite{hyafil1976constructing}, which is why algorithms
like C4.5 are greedy and nonbacktracking \cite{quinlan1993c4}, favouring
maximising local optima only at each iteration. An ancestor to C4.5, CLS,
uses a lookahead to a fixed depth similar to Minimax \cite{quinlan1986induction},
which can be computational expensive. Given we usually want supervised
learning to scale to large numbers of learning examples, it is arguably preferable
to take the more common approach of aiding the learning process with
data reduction -- e.g. removing ingredients that don't match some acceptance threshold
as suggested above -- or divide-and-conquer approaches where perhaps clustering is
used to group recipes that are similar so that different classifiers can be
trained on those specific clusters only. It is also common in machine learning
to use expert domain knowledge where possible to guide improvements to the
models.

For the cuisine classification problem, we will define \emph{minimum occurrence}
and \emph{maximum occurrence} thresholds below and above which we will remove
ingredients attributes. They will be set initially to $O$ and $\infty$
respectively so the first models will be constructed from every ingredient
attribute, but they will then provide a baseline against which we can compare
models learnt from different occurrence thresholds so as to evaluate whether
improvements are made through data reduction in this way.

Another consideration for data reduction can be to reduce dimensionality by creating
compound attributes from ingredients that strongly correlate. For instance, if
we were to decide either through similarity calculations or domain knowledge
that salt and pepper always appear in recipes together and negligibly does
one appear without the other, we can replace these distrinct attributes with a compound
attribute \emph{salt-pepper} that is \emph{true} for all recipes that has either.
Again, this reduces complexity and can even smooth out noise \cite{han2006data} and
thus do more to increase accuracy than to reduce it.

\subsubsection{Similarity and Dissimilarity}

Given all the ingredients attributes are asymmetric, binary attributes, we can ignore
the cuisine class attribute for now and calculate the similarity or distances
between recipes using the \emph{Jaccard distance}: \cite{han2006data}

\begin{equation}
J_{\delta}(A,B) = 1 - J(A,B) = { { |A \cup B| - |A \cap B| } \over |A \cup B| }
\end{equation}

\noindent where $A$ and $B$ are the sets of ingredients that appear in two given
recipes. We can see such a matrix on a sample of five reasonably similar recipes
in Table~\ref{tab:distance-matrix}.

\begin{table}
  \centering
  \begin{tabular}{| p{2cm} | p{2cm} | p{2cm} | p{2cm} | p{2cm} | p{2cm} |}
    \hline
     & Amaretto vanilla custard & Cr\`eme br\^ul\'ee & Raspberry ripple ice cream & Apricot upside-down tart & American pancakes \\
    \hline
    Amaretto vanilla custard   & 0    & 0 & 0.17 & 0.9 & 0.92 \\
    \hline
    Cr\`eme br\^ul\'ee         & 0    & 0 &      &     &      \\
    \hline
    Raspberry ripple ice cream & 0.17 &   & 0    &     &      \\
    \hline
    Apricot upside-down tart   & 0.9  &   &      & 0   &      \\
    \hline
    American pancakes          & 0.92 &   &      &     & 0    \\
    \hline
  \end{tabular}
  \caption{Distance matrix between five dessert recipes}
  \label{tab:distance-matrix}
\end{table}

One immediate observation from Table~\ref{tab:distance-matrix} is that there
are two recipes that come out with a distance of $0$, implying they have
identical ingredients. This appears to be indeed the case. Even more interestingly,
the cr\`eme br\^ul\'ee is classified as \emph{French} whereas the
amaretto vanilla custard is classified as \emph{British}. It is clear that any classification
of the cuisine based solely on the ingredients is going to put these two recipes in
the same class (although which it will choose is less clear) and thus we can see
\emph{before even running any supervised learning} that there will be errors when using
just ingredients as the training attributes. It is also particularly of note when
we refer to domain knowledge on
cooking and cuisine that our first such case is a confusion between a French and a British
dish given these are two cuisines with significant overlap from centuries of cultural mixing
and proximity.

A further observation is that the sparse nature of the number of ingredients used
on average per recipe out of all possible ingredients means that it is very easy for two
recipes that have a few ingredients in common to come out with a large distance apart such
as 0.9. The mean distance between any two classified recipes in this dataset is 0.94, which
indicates a very sparse dataset in general.

\subsection{Training a Cuisine Classifier}
\subsection{Evaluating the Model}
\subsection{Improving the Model}

\section{Discussion}
\subsection{Difficulties}
\subsection{Observations}
\subsection{Further Possibilties}

\bibliographystyle{cell}
\bibliography{bibtex}
\end{document}
